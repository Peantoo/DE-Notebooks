{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1iwAmRn6_PobdKb6VOUXZtPxLRmfM9Lr7",
      "authorship_tag": "ABX9TyN5oSkUAJTQezBjJwHdMwyP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Peantoo/DE-Notebooks/blob/main/DE-Exercise1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsCjy_Dk-cyk"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "np.random.seed(0) "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data\n",
        "## Read in CSV file\n",
        "This is on my Google drive, but it can be brought in from anywhere. I'm bringing in v5 from the dataset. \n",
        "\n",
        "There are many ways to read in the data, but this is easiest for me as it lets me quickly access the data with Google Colab from any PC.\n",
        " \n",
        "I always name the first CSV \"RAW\" so that it can be referenced later for comparison."
      ],
      "metadata": {
        "id": "qxztsgWrlynz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RAW = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data Sets/NFL Play by Play 2009-2018 (v5).csv')"
      ],
      "metadata": {
        "id": "ddn512VW-zkk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70d416e8-5e18-4f93-a3b4-fea27969691f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (42,166,167,168,169,174,175,178,179,182,183,188,189,190,191,194,195,203,204,205,218,219,220,231,232,233,238,240,241,249) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## First inspection of the data to get a feel for what I'm working with. \n",
        "\n",
        "RAW.describe()\n"
      ],
      "metadata": {
        "id": "bqqsp0wMADv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#That's a lot of data. First thing I notice is that some columns have zero in count, meaning there's no data. There's also a lot of columns missing. I want to see them all.\n",
        "\n",
        "RAW.info(verbose=True)"
      ],
      "metadata": {
        "id": "cjkngCKUCnCY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "291b05d6-de86-497b-d689-907107d2265b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 449371 entries, 0 to 449370\n",
            "Data columns (total 255 columns):\n",
            " #    Column                                Dtype  \n",
            "---   ------                                -----  \n",
            " 0    play_id                               int64  \n",
            " 1    game_id                               int64  \n",
            " 2    home_team                             object \n",
            " 3    away_team                             object \n",
            " 4    posteam                               object \n",
            " 5    posteam_type                          object \n",
            " 6    defteam                               object \n",
            " 7    side_of_field                         object \n",
            " 8    yardline_100                          float64\n",
            " 9    game_date                             object \n",
            " 10   quarter_seconds_remaining             float64\n",
            " 11   half_seconds_remaining                float64\n",
            " 12   game_seconds_remaining                float64\n",
            " 13   game_half                             object \n",
            " 14   quarter_end                           int64  \n",
            " 15   drive                                 int64  \n",
            " 16   sp                                    int64  \n",
            " 17   qtr                                   int64  \n",
            " 18   down                                  float64\n",
            " 19   goal_to_go                            float64\n",
            " 20   time                                  object \n",
            " 21   yrdln                                 object \n",
            " 22   ydstogo                               int64  \n",
            " 23   ydsnet                                int64  \n",
            " 24   desc                                  object \n",
            " 25   play_type                             object \n",
            " 26   yards_gained                          float64\n",
            " 27   shotgun                               int64  \n",
            " 28   no_huddle                             int64  \n",
            " 29   qb_dropback                           float64\n",
            " 30   qb_kneel                              int64  \n",
            " 31   qb_spike                              int64  \n",
            " 32   qb_scramble                           int64  \n",
            " 33   pass_length                           object \n",
            " 34   pass_location                         object \n",
            " 35   air_yards                             float64\n",
            " 36   yards_after_catch                     float64\n",
            " 37   run_location                          object \n",
            " 38   run_gap                               object \n",
            " 39   field_goal_result                     object \n",
            " 40   kick_distance                         float64\n",
            " 41   extra_point_result                    object \n",
            " 42   two_point_conv_result                 object \n",
            " 43   home_timeouts_remaining               int64  \n",
            " 44   away_timeouts_remaining               int64  \n",
            " 45   timeout                               float64\n",
            " 46   timeout_team                          object \n",
            " 47   td_team                               object \n",
            " 48   posteam_timeouts_remaining            float64\n",
            " 49   defteam_timeouts_remaining            float64\n",
            " 50   total_home_score                      int64  \n",
            " 51   total_away_score                      int64  \n",
            " 52   posteam_score                         float64\n",
            " 53   defteam_score                         float64\n",
            " 54   score_differential                    float64\n",
            " 55   posteam_score_post                    float64\n",
            " 56   defteam_score_post                    float64\n",
            " 57   score_differential_post               float64\n",
            " 58   no_score_prob                         float64\n",
            " 59   opp_fg_prob                           float64\n",
            " 60   opp_safety_prob                       float64\n",
            " 61   opp_td_prob                           float64\n",
            " 62   fg_prob                               float64\n",
            " 63   safety_prob                           float64\n",
            " 64   td_prob                               float64\n",
            " 65   extra_point_prob                      float64\n",
            " 66   two_point_conversion_prob             float64\n",
            " 67   ep                                    float64\n",
            " 68   epa                                   float64\n",
            " 69   total_home_epa                        float64\n",
            " 70   total_away_epa                        float64\n",
            " 71   total_home_rush_epa                   float64\n",
            " 72   total_away_rush_epa                   float64\n",
            " 73   total_home_pass_epa                   float64\n",
            " 74   total_away_pass_epa                   float64\n",
            " 75   air_epa                               float64\n",
            " 76   yac_epa                               float64\n",
            " 77   comp_air_epa                          float64\n",
            " 78   comp_yac_epa                          float64\n",
            " 79   total_home_comp_air_epa               float64\n",
            " 80   total_away_comp_air_epa               float64\n",
            " 81   total_home_comp_yac_epa               float64\n",
            " 82   total_away_comp_yac_epa               float64\n",
            " 83   total_home_raw_air_epa                float64\n",
            " 84   total_away_raw_air_epa                float64\n",
            " 85   total_home_raw_yac_epa                float64\n",
            " 86   total_away_raw_yac_epa                float64\n",
            " 87   wp                                    float64\n",
            " 88   def_wp                                float64\n",
            " 89   home_wp                               float64\n",
            " 90   away_wp                               float64\n",
            " 91   wpa                                   float64\n",
            " 92   home_wp_post                          float64\n",
            " 93   away_wp_post                          float64\n",
            " 94   total_home_rush_wpa                   float64\n",
            " 95   total_away_rush_wpa                   float64\n",
            " 96   total_home_pass_wpa                   float64\n",
            " 97   total_away_pass_wpa                   float64\n",
            " 98   air_wpa                               float64\n",
            " 99   yac_wpa                               float64\n",
            " 100  comp_air_wpa                          float64\n",
            " 101  comp_yac_wpa                          float64\n",
            " 102  total_home_comp_air_wpa               float64\n",
            " 103  total_away_comp_air_wpa               float64\n",
            " 104  total_home_comp_yac_wpa               float64\n",
            " 105  total_away_comp_yac_wpa               float64\n",
            " 106  total_home_raw_air_wpa                float64\n",
            " 107  total_away_raw_air_wpa                float64\n",
            " 108  total_home_raw_yac_wpa                float64\n",
            " 109  total_away_raw_yac_wpa                float64\n",
            " 110  punt_blocked                          float64\n",
            " 111  first_down_rush                       float64\n",
            " 112  first_down_pass                       float64\n",
            " 113  first_down_penalty                    float64\n",
            " 114  third_down_converted                  float64\n",
            " 115  third_down_failed                     float64\n",
            " 116  fourth_down_converted                 float64\n",
            " 117  fourth_down_failed                    float64\n",
            " 118  incomplete_pass                       float64\n",
            " 119  interception                          float64\n",
            " 120  punt_inside_twenty                    float64\n",
            " 121  punt_in_endzone                       float64\n",
            " 122  punt_out_of_bounds                    float64\n",
            " 123  punt_downed                           float64\n",
            " 124  punt_fair_catch                       float64\n",
            " 125  kickoff_inside_twenty                 float64\n",
            " 126  kickoff_in_endzone                    float64\n",
            " 127  kickoff_out_of_bounds                 float64\n",
            " 128  kickoff_downed                        float64\n",
            " 129  kickoff_fair_catch                    float64\n",
            " 130  fumble_forced                         float64\n",
            " 131  fumble_not_forced                     float64\n",
            " 132  fumble_out_of_bounds                  float64\n",
            " 133  solo_tackle                           float64\n",
            " 134  safety                                float64\n",
            " 135  penalty                               float64\n",
            " 136  tackled_for_loss                      float64\n",
            " 137  fumble_lost                           float64\n",
            " 138  own_kickoff_recovery                  float64\n",
            " 139  own_kickoff_recovery_td               float64\n",
            " 140  qb_hit                                float64\n",
            " 141  rush_attempt                          float64\n",
            " 142  pass_attempt                          float64\n",
            " 143  sack                                  float64\n",
            " 144  touchdown                             float64\n",
            " 145  pass_touchdown                        float64\n",
            " 146  rush_touchdown                        float64\n",
            " 147  return_touchdown                      float64\n",
            " 148  extra_point_attempt                   float64\n",
            " 149  two_point_attempt                     float64\n",
            " 150  field_goal_attempt                    float64\n",
            " 151  kickoff_attempt                       float64\n",
            " 152  punt_attempt                          float64\n",
            " 153  fumble                                float64\n",
            " 154  complete_pass                         float64\n",
            " 155  assist_tackle                         float64\n",
            " 156  lateral_reception                     float64\n",
            " 157  lateral_rush                          float64\n",
            " 158  lateral_return                        float64\n",
            " 159  lateral_recovery                      float64\n",
            " 160  passer_player_id                      object \n",
            " 161  passer_player_name                    object \n",
            " 162  receiver_player_id                    object \n",
            " 163  receiver_player_name                  object \n",
            " 164  rusher_player_id                      object \n",
            " 165  rusher_player_name                    object \n",
            " 166  lateral_receiver_player_id            object \n",
            " 167  lateral_receiver_player_name          object \n",
            " 168  lateral_rusher_player_id              object \n",
            " 169  lateral_rusher_player_name            object \n",
            " 170  lateral_sack_player_id                float64\n",
            " 171  lateral_sack_player_name              float64\n",
            " 172  interception_player_id                object \n",
            " 173  interception_player_name              object \n",
            " 174  lateral_interception_player_id        object \n",
            " 175  lateral_interception_player_name      object \n",
            " 176  punt_returner_player_id               object \n",
            " 177  punt_returner_player_name             object \n",
            " 178  lateral_punt_returner_player_id       object \n",
            " 179  lateral_punt_returner_player_name     object \n",
            " 180  kickoff_returner_player_name          object \n",
            " 181  kickoff_returner_player_id            object \n",
            " 182  lateral_kickoff_returner_player_id    object \n",
            " 183  lateral_kickoff_returner_player_name  object \n",
            " 184  punter_player_id                      object \n",
            " 185  punter_player_name                    object \n",
            " 186  kicker_player_name                    object \n",
            " 187  kicker_player_id                      object \n",
            " 188  own_kickoff_recovery_player_id        object \n",
            " 189  own_kickoff_recovery_player_name      object \n",
            " 190  blocked_player_id                     object \n",
            " 191  blocked_player_name                   object \n",
            " 192  tackle_for_loss_1_player_id           object \n",
            " 193  tackle_for_loss_1_player_name         object \n",
            " 194  tackle_for_loss_2_player_id           object \n",
            " 195  tackle_for_loss_2_player_name         object \n",
            " 196  qb_hit_1_player_id                    object \n",
            " 197  qb_hit_1_player_name                  object \n",
            " 198  qb_hit_2_player_id                    object \n",
            " 199  qb_hit_2_player_name                  object \n",
            " 200  forced_fumble_player_1_team           object \n",
            " 201  forced_fumble_player_1_player_id      object \n",
            " 202  forced_fumble_player_1_player_name    object \n",
            " 203  forced_fumble_player_2_team           object \n",
            " 204  forced_fumble_player_2_player_id      object \n",
            " 205  forced_fumble_player_2_player_name    object \n",
            " 206  solo_tackle_1_team                    object \n",
            " 207  solo_tackle_2_team                    object \n",
            " 208  solo_tackle_1_player_id               object \n",
            " 209  solo_tackle_2_player_id               object \n",
            " 210  solo_tackle_1_player_name             object \n",
            " 211  solo_tackle_2_player_name             object \n",
            " 212  assist_tackle_1_player_id             object \n",
            " 213  assist_tackle_1_player_name           object \n",
            " 214  assist_tackle_1_team                  object \n",
            " 215  assist_tackle_2_player_id             object \n",
            " 216  assist_tackle_2_player_name           object \n",
            " 217  assist_tackle_2_team                  object \n",
            " 218  assist_tackle_3_player_id             object \n",
            " 219  assist_tackle_3_player_name           object \n",
            " 220  assist_tackle_3_team                  object \n",
            " 221  assist_tackle_4_player_id             float64\n",
            " 222  assist_tackle_4_player_name           float64\n",
            " 223  assist_tackle_4_team                  float64\n",
            " 224  pass_defense_1_player_id              object \n",
            " 225  pass_defense_1_player_name            object \n",
            " 226  pass_defense_2_player_id              object \n",
            " 227  pass_defense_2_player_name            object \n",
            " 228  fumbled_1_team                        object \n",
            " 229  fumbled_1_player_id                   object \n",
            " 230  fumbled_1_player_name                 object \n",
            " 231  fumbled_2_player_id                   object \n",
            " 232  fumbled_2_player_name                 object \n",
            " 233  fumbled_2_team                        object \n",
            " 234  fumble_recovery_1_team                object \n",
            " 235  fumble_recovery_1_yards               float64\n",
            " 236  fumble_recovery_1_player_id           object \n",
            " 237  fumble_recovery_1_player_name         object \n",
            " 238  fumble_recovery_2_team                object \n",
            " 239  fumble_recovery_2_yards               float64\n",
            " 240  fumble_recovery_2_player_id           object \n",
            " 241  fumble_recovery_2_player_name         object \n",
            " 242  return_team                           object \n",
            " 243  return_yards                          float64\n",
            " 244  penalty_team                          object \n",
            " 245  penalty_player_id                     object \n",
            " 246  penalty_player_name                   object \n",
            " 247  penalty_yards                         float64\n",
            " 248  replay_or_challenge                   int64  \n",
            " 249  replay_or_challenge_result            object \n",
            " 250  penalty_type                          object \n",
            " 251  defensive_two_point_attempt           float64\n",
            " 252  defensive_two_point_conv              float64\n",
            " 253  defensive_extra_point_attempt         float64\n",
            " 254  defensive_extra_point_conv            float64\n",
            "dtypes: float64(135), int64(18), object(102)\n",
            "memory usage: 874.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make a dataframe from a copy of the RAW file to begin actual work on. Keep df_RAW so I can compare the dataframes later.\n",
        "\n",
        "df_RAW = pd.DataFrame(RAW.copy())\n",
        "df = df_RAW.copy()"
      ],
      "metadata": {
        "id": "mvUU2JgrAJlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape # Will need to clean up both columns and rows. Start with Columns as that will yield more cuts than Rows."
      ],
      "metadata": {
        "id": "6X-QkQy6ZhCz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a64ce87e-03a7-4cb7-e7c1-1e4037233223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(449371, 255)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To see all of the rows, we much change the number of rows displayed.\n",
        "\n",
        "pd.set_option(\"display.max_rows\", 300)\n"
      ],
      "metadata": {
        "id": "PAEciuOFF3Rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#I'd like to see what it actually looks like as a dataframe. It's obvious that some have 0 and some have NaN. It's a good idea to find out why and what correlation exists among columns. \n",
        "df.sample(20)"
      ],
      "metadata": {
        "id": "6uCFbQjjFGb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exploration & Assessment of missing data points and values\n",
        "How many entries are NaN in the dataframe? How many entries are NaN in each column? This will tell me if any columns can be dropped. I know I can just immediately drop all columns and rows that are entirelly NaN, but I like to see the data first before erasing anything. \n",
        "\n",
        "df.isna().sum(axis=0) will display the number of NaN in each column in a new set of rows.\n",
        "\n",
        "I combined the two topics of Exploration and Assessment as I tend to do both at the same time. "
      ],
      "metadata": {
        "id": "D_TANO8omZwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#How many NaN total?\n",
        "num_nan = df.isna().sum().sum()\n",
        "print(num_nan)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWtWjK4iLfOF",
        "outputId": "df6382d0-1c6b-44fb-97a1-b993fce0faf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44121484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Percentage of NaN to Real?\n",
        "total = (df.isna().sum().sum())+(df.count().sum().sum())\n",
        "ratio = ((num_nan)/(total))*100\n",
        "print(ratio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWBy7NuFL-t2",
        "outputId": "9fdd2b80-5381-41ce-8aad-072a5f9a8303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38.50391490571942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Display Total Number of NaN in each column\n",
        "df.isna().sum(axis=0)"
      ],
      "metadata": {
        "id": "rDjFNOOvUoPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A quick analysis tells me that something isn't quite right, as the number 12874 shows up a lot, particularly in areas where the data should be common to every game, like \"Touchdowns\" and \"Pass attempt.\" These are areas where there should almost always be a value. I don't think I've seen a game where they never tried to pass. This tells me that the recorded games that have a null value in those areas probably need to be culled, as they will not contain any useful data. I would double check the CSV for those games, then delete those 12874 games.\n",
        "\n",
        "I also noticed that the percentage of NaN in the whole set is oddly high. This is probably due to a large number of values that should be recorded as 0, not NaN. The columns with high amounts of null values for rarer things like \"penalty yards,\" should not be culled, as these are rarer things that could influence the game. This shows that a high number of null values isn't necessarily a bad thing and you shouldn't always remove categories with high NaN numbers. For these, I would replace NaN with zero. "
      ],
      "metadata": {
        "id": "NybfA8hmVwON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Check for Columns where every value is NaN\n",
        "df[df.columns[df.isna().any()]].isna().sum() * 100 / df.shape[0]\n",
        "# Use this to find the percentage of the column that's NaN. Useful for getting rid of columns with no data or\n",
        "#deciding which columns to fill with 0's or synthetic data. Does not include columns with no NaN data."
      ],
      "metadata": {
        "id": "4lQCImdzRkev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Any column where the value is 100 can safely be cut as it contains no information. I also now feel confident in deleting all rows where every column is NaN and vice-versa. "
      ],
      "metadata": {
        "id": "e913ZewYX9Bz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Drop missing values"
      ],
      "metadata": {
        "id": "5vWA81w3oOtZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropping values is never what I want to do, but sometimes it's necessary. I always start with getting rid of any columns with no data. I then move on to rows. I then check to see if any important data is missing and whether that row can be salvaged. After that, I then check to see the methods for filling missing data. This is probably the most time consuming part of the process, but it can also make the biggest difference if you're wanting high fidelity data sets."
      ],
      "metadata": {
        "id": "xhsxohDRHvl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cut Columns and Rows with NaN for all values. I expect that if I remove any rows where all columns are NaN, then I will clear out the 12874 games from before.\n",
        "df = df.dropna(axis=1, how='all')  \n",
        "df = df.dropna(axis=0, how='all')"
      ],
      "metadata": {
        "id": "9fdg3cBMCriA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = pd.Series(df.shape)\n",
        "a"
      ],
      "metadata": {
        "id": "W7IMizHtyImi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check \n",
        "df[df.columns[df.isnull().any()]].isnull().sum() * 100 / df.shape[0]"
      ],
      "metadata": {
        "id": "vtOF5xkdAguW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I noticed that this didn't get rid of all the columns with 2.86% NaN (the 12874 rows previously mention.) I need to do some further assessment of one of them to see what's going on. I will pick one that I know should have a value."
      ],
      "metadata": {
        "id": "Z6I4cZ8BhEpH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['incomplete_pass'].isnull()]"
      ],
      "metadata": {
        "id": "ll_MzxTrEKBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows me that there are just some games where there was just no recorded data other than the game_id and the teams that were supposed to play. These games contain only metadata and are therefor not useful. Since I know that at the very least, every game should have certain values, I can be sure that I'm not getting rid of any non-scoring game or any outlier game if I get rid of rows with NaN for many columns."
      ],
      "metadata": {
        "id": "O08sJm-vhmf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Drop a row if it has NaN in the following categories. While others are important, if a game has NaN for all of these values, it probably isn't worth recording.\n",
        "df = df.dropna(subset=[\"pass_attempt\",\"incomplete_pass\",\"rush_attempt\",\"tackled_for_loss\",\"touchdown\"], how='all')"
      ],
      "metadata": {
        "id": "sXrK4APMh3Sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = pd.Series(df.shape)\n",
        "b"
      ],
      "metadata": {
        "id": "Ri9c0ZZwyS7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am just checking to make sure that I am only getting rid of the same number of columns as I saw previously and no extras accidentally got lumped in."
      ],
      "metadata": {
        "id": "0piWSJe0HkDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a-b"
      ],
      "metadata": {
        "id": "jU_I-RKRylFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check and create a new dataframe called dfpercents so I can easily split the remaining into two groups.\n",
        "dfpercents = pd.DataFrame(df[df.columns[df.isnull().any()]].isnull().sum() * 100 / df.shape[0])\n",
        "dfpercents.columns=['Percents']\n",
        "dfpercents"
      ],
      "metadata": {
        "id": "6uTBlY0ZjNEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#low_mask=dfpercents[0]>=10 \n",
        "high_mask = dfpercents.query('Percents >= 5')\n",
        "low_mask = dfpercents.query('Percents < 5')"
      ],
      "metadata": {
        "id": "WjDKh5w3Qzs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Success! Now we are only left with fields that either should have a value but an error caused one to be left out, or, a field that rarely occurs in a game, so that field (and fields directly related to it) are left with a null value for the majority of games. \n",
        "\n"
      ],
      "metadata": {
        "id": "an9yKLXZju4T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fill in missing values\n",
        "For fields with a low number of null values, replacing them with the mean of the field is probably acceptable. For columns with a high number of NaN, it is probably best to replace with 0 to signify that the event did not occur in the game. \n",
        "\n",
        "The method I'm using for this particular dataset is probably not the most optimized, but I've found it works. Since there are 3 categories of data, clean, incorrect, and empty (change to zero), I want to split them up, apply transformations to each, then stitch them back together. \n",
        "\n",
        "I will use a \"low mask\" to select the names of all the columns that have a low percentage of NaN values and fill in those values with a mean for the column.\n",
        "\n",
        "I will use a \"high mask\" to select the names of any column with a large amount of NaN values and change those to zeroes."
      ],
      "metadata": {
        "id": "ockjvhVJodzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "low_columns = low_mask.reset_index()\n",
        "low_columns = low_columns['index'].to_list()\n",
        "low_columns"
      ],
      "metadata": {
        "id": "EVImI3_QPn77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now make a list of highs - same way basically.\n",
        "high_columns = high_mask.reset_index()\n",
        "high_columns = high_columns['index'].to_list()\n",
        "high_columns"
      ],
      "metadata": {
        "id": "lDHNZDT_bi0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I just need to use these lists to replace the values. Then I should have no more NaN values without having to delete any more potentially useful data than absolutely necessary."
      ],
      "metadata": {
        "id": "Yl6yar8rcFtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "SQ15SotUx2ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = pd.Series(high_columns)\n",
        "#print(x)\n",
        "y = pd.Series(low_columns)\n",
        "#print(y)\n",
        "dfx = pd.DataFrame(df[x].fillna(value = 0))\n",
        "# Check if it worked\n",
        "dfx\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8KTSAS6ucE6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now I need to find the mean of JUST the columns I mean to change. I do this because finding the means of all 250 columns takes a long time, but finding just ~50 columns is much quicker.\n",
        "mean = df[y].mean()\n",
        "dfy = pd.DataFrame(df[y].fillna(value = mean))"
      ],
      "metadata": {
        "id": "n4gBWIz8lKLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfy"
      ],
      "metadata": {
        "id": "dPEG3C-276ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Join the two fixed dataframes into one for later integration with the original dataframe.\n",
        "newdf = pd.concat([dfx, dfy], axis=1)\n",
        "newdf"
      ],
      "metadata": {
        "id": "dEXVHAovAseT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.update(newdf) #Use Pandas' update function to compare incoming data with old data and overwrite old values. This should leave the original data with no NaN values alone."
      ],
      "metadata": {
        "id": "jmMCGTtW-4Sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finished Data Set\n",
        "While I'm 100% sure a lot of this can now be optimized and cleaned up, I wanted to leave it like this to show my train of thought. I am constantly checking to see what happened when I ran my code, I like to continue to compare previous versions to what I've done, and I like to take things step by step. It may take a little bit longer, but it reduces errors and enables me to get a better feel for the data.\n",
        "\n",
        "Some of the columns in this dataset can probably be tweaked better than a simple mean, but as I'm time limited, I can't go through them column by column to determine the best course of action for each type of data. For example, I could hunt for outliers by implementing a mean() and max()/min() comparison and checking to see if any values were over a certain threshold above or below the mean (touchdowns >= 30 or something). I still think the results came out the way I wanted, so I'm happy with this for now. "
      ],
      "metadata": {
        "id": "cIXATbB5Bnm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "RMBIPJnYBhDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Final Check\n",
        "df[df.columns[df.isna().any()]].isna().sum() * 100 / df.shape[0]"
      ],
      "metadata": {
        "id": "Z2OpN54LCV-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Somewhere, somehow, very small percentages are still Null values. This will take deep digging. Or, I can just apply fillna() to the entire df and be done with it!"
      ],
      "metadata": {
        "id": "BUvND1SoCq4h"
      }
    }
  ]
}